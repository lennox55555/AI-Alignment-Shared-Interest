## Planned Growth
This repository is the beginning of a much larger journey into **AI alignment**. Moving forward, I plan to:
- **Explore More Models**: Analyze different architectures (e.g., transformers, RNNs) to understand alignment across various types of AI systems.
- **Expand Dataset Scope**: Incorporate **medical, natural language processing**, and **self-driving car** datasets to see how alignment patterns differ in critical real-world applications.
- **Develop New Metrics**: As AI alignment research evolves, I aim to contribute by developing new methods to measure alignment beyond saliency.
- **Interactive Tools**: Build tools for interactive model analysis and comparison to allow broader engagement in the field of AI alignment research.

## Why AI Alignment?
AI alignment is crucial for the future of AI. Models need to make decisions that align with human values, especially in high-stakes applications like healthcare and autonomous vehicles. I’m driven by the desire to better understand how AI models think and ensure that they can be trusted to act in ways that are aligned with human intentions.

Stay tuned for more updates as I continue to learn and contribute to the growing field of **AI alignment**!

---

Feel free to explore the notebooks, experiment with the models, and contribute to the project. Let’s ensure AI aligns with the values and reasoning we expect!
